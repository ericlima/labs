{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import *\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.\\\n",
    "                option(\"sep\", \";\").\\\n",
    "                option(\"header\", \"true\").\\\n",
    "                csv(\"/user/datacovid/HIST_PAINEL_COVIDBR_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando no dataFrame somente os municipios não nulos\n",
    "municipios = test.filter(test.municipio.isNotNull()).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em um novo dataframe somente os Municipios\n",
    "mc = municipios.select(municipios.municipio).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o Database no HIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"CREATE DATABASE covid location '/user/hive/warehouse/covid19'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|       banco|\n",
      "|       covid|\n",
      "|     covid19|\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando a criação Banco covid19\n",
    "sqlContext.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"use covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"CREATE TABLE test(regiao string, estado string, municipio string, codUf string, codMun string, codRegiaoSaude string, nomeRegiaoSaude string, data string, semanaEpi string, populacaoTCU2019 string, casosAcumulado string, casosNovos string, obitosAcumulado string, obitosNovos string, recuperadosNovos string, emAcompanhamentoNovos string, interiorMetropolitana string)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando os arquivos por municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para construção de uma lista de municípios\n",
    "list_municipios  = []\n",
    "for row in mc.collect():\n",
    "    list_municipios.append(row.municipio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para separar os dados do DF por municipio, assim otimizar e particionar por municipio, assim como pede no exercicio.\n",
    "for data in list_municipios:\n",
    "    df = test.filter(test.municipio.isin(data))\n",
    "    table = data.replace(\" \", \"_\")\n",
    "    table = table.lower()\n",
    "    # sqlContext.sql(\"ALTER TABLE test ADD PARTITION(municipio=\"+ data +\"))\n",
    "    df.write.saveAsTable(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Códigos aleatórios verificar se necessário\n",
    "test.filter(test.municipio.isin(municipios.municipio)).show()\n",
    "test.createOrReplaceTempView(\"COVIDBR_2020_Parte1\")\n",
    "df = spark.sql(\"SELECT * FROM COVIDBR_2020_Parte1 where municipio <> 'null'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montar as 3 vizualizações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* | Casos Recuperados, Em acompanhamento | 17.262.646, 1.065.477\n",
    "* | Casos confirmados ( Acumulado, casos novos, Incidência) | 18.855.015, 62.504, 8972,3\n",
    "* | Óbitos confirmados ( Acumulado, casos novos, letalidade, mortalidade) | 526.892, 1.780, 2,8%, 250,7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela com todos os dados\n",
    "test.write.partitionBy(test.municipio).parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar Visualização de Recuperados e Em acompanhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datetime.now()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datetime.now()\n",
    "print(y-x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos Recuperados, Em acompanhamento\n",
    "\n",
    "x = datetime.now()\n",
    "\n",
    "Casos_Recuperados_DF = \\\n",
    "    sqlContext.sql( \\\n",
    "        \"SELECT \\\n",
    "            FORMAT_NUMBER(SUM(Recuperadosnovos),0) AS Casos_Recuperados, \\\n",
    "            FORMAT_NUMBER(SUM(emAcompanhamentoNovos),0) AS Em_Acompanhamento \\\n",
    "        FROM \\\n",
    "            alldata \\\n",
    "        WHERE \\\n",
    "            data = '2021-07-06'\").show()\n",
    "\n",
    "y = datetime.now()\n",
    "print(\"TEMPO DE EXECUÇÃO -->\", y-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----------+\n",
      "| Acumulado|Casos_Novos|Incidencia|\n",
      "+----------+-----------+----------+\n",
      "|19,908,799|     68,109|     3,158|\n",
      "+----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Casos confirmados\n",
    "\n",
    "Casos_Confirmados_DF = \\\n",
    "    spark.sql( \\\n",
    "        \"SELECT \\\n",
    "            FORMAT_NUMBER((SUM(Recuperadosnovos) + SUM(emAcompanhamentoNovos) + SUM(obitosAcumulado)),0) AS Acumulado, \\\n",
    "            (\\\n",
    "                SELECT \\\n",
    "                    FORMAT_NUMBER(SUM(casosNovos),0) \\\n",
    "                FROM \\\n",
    "                    alldata \\\n",
    "                WHERE \\\n",
    "                    data = '2021-07-05' \\\n",
    "             ) AS Casos_Novos, \\\n",
    "            FORMAT_NUMBER(((SUM(Recuperadosnovos) + SUM(emAcompanhamentoNovos) + SUM(obitosAcumulado)) * 100000) / SUM(populacaoTCU2019), 0) as Incidencia \\\n",
    "        FROM \\\n",
    "            alldata \\\n",
    "        WHERE \\\n",
    "            data = '2021-07-06'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------+-----------+\n",
      "|Obitos_acumulados|Obitos_novos|Letalidade|Mortalidade|\n",
      "+-----------------+------------+----------+-----------+\n",
      "|        1,580,676|       2,085|      7.94|     250.73|\n",
      "+-----------------+------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Óbitos Confirmados\n",
    "\n",
    "Casos_Obtos_DF = \\\n",
    "    spark.sql( \\\n",
    "        \"SELECT \\\n",
    "            FORMAT_NUMBER(((SUM(obitosAcumulado))),0) AS Obitos_acumulados, \\\n",
    "            (\\\n",
    "                SELECT \\\n",
    "                    FORMAT_NUMBER(SUM(obitosNovos),0) \\\n",
    "                FROM \\\n",
    "                    alldata \\\n",
    "                WHERE \\\n",
    "                    data = '2021-07-05' \\\n",
    "            ) AS Obitos_novos, \\\n",
    "            ROUND(((SUM(obitosAcumulado)) * 100) / (SUM(Recuperadosnovos) + SUM(emAcompanhamentoNovos) + (SUM(obitosAcumulado))),2) AS Letalidade, \\\n",
    "            ROUND(((((SUM(obitosAcumulado))) * 100000)) / SUM(populacaoTCU2019), 2) AS Mortalidade \\\n",
    "        FROM \\\n",
    "            alldata \\\n",
    "        WHERE data = '2021-07-06'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando Casos Recuperados, Em acompanhamento em tabela Hive\n",
    "\n",
    "Casos_Recuperados_DF.write.saveAsTable(\"casos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo a tabela casos\n",
    "\n",
    "sqlContext.sql(\"SELECT * casos\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Casos_Confirmados_DF.write.mode(\"overwrite\").option(\"compression\", \"snappy\").parquet(\"/user/datacovid/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
